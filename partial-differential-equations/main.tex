\documentclass[11pt]{penrose}

\usepackage{mathsphystools}
\usepackage{thmstyles}

\newcommand{\utt}{u_{tt}}
\newcommand{\uxt}{u_{xt}}
\newcommand{\uxx}{u_{xx}}
\newcommand{\uyy}{u_{yy}}
\newcommand{\uxy}{u_{xy}}

\newcommand{\missing}[1]{{\color{red}#1}}

\title{MATH 353: Partial Differential Equations}
\subtitle{Brief lecture notes}
\author{Rashid M. Talha}
\affiliation{School of Natural Sciences, NUST}
\date{\today}
\begin{document}

\maketitle

\textbf{Textbook:} Linear Partial Differential Equations for Scientists and Engineers, Tyn Myint-U and Lokenath Debnath

\textbf{Disclaimer:} This document most likely contains some errors --- use with caution. I have rephrased or paraphrased the content in most of the sections. Some examples may be missing. The numbering that I have used for sections, definitions, theorems, etc will not match the numbering given in the lectures.

\section{Introduction}
A general partial differential equation (PDE) can be expressed as
\begin{equation}
    F(x,y,\dots, u, u_x, u_y, \dots, u_{xx}, u_{xy}, \dots) = 0
\end{equation}
where $x, y, \dots$ are independent variables and $u = u(x,y,\dots)$ is an unknown function. The terms $u_x, u_y, u_{xy}, \dots$ represent derivatives of $u$. For example,
\begin{equation*}
    u_{xy} = \frac{\pd^2 u}{\pd y \pd x}.
\end{equation*}

The unknown function $u$ is defined over some domain $D \subseteq \R^{n}$.
\begin{equation}
    u : D \to \R
    \qquad\text{with}\qquad
    (x, y, \dots) \mapsto u(x, y, \dots)
\end{equation}

The goal is to find a suitable function $u$ (either explicitly or implicitly) that satisfies the given PDE and any additional initial-boundary data.

\begin{ndfn}
    A PDE is said to be well-posed if
    \begin{enumerate}
        \item It has a solution; and
        \item that solution is unique; and
        \item that solution depends on the prescribed initial/boundary data continuously.
    \end{enumerate}
\end{ndfn}

\section{General Classification}

The order of the PDE is the order of the highest order derivative term.

A PDE where each term containing the unknown function or its derivatives appears linearly, is called a linear PDE. In particular, a general 2nd order PDE in $n$ variables takes the form
\begin{equation}
    \sum_{i,j=1}^{n} a_{i,j} u_{x_i x_j} + \sum_{i=1}^{n} b_i u_{x_i} + c u = d.
\end{equation}
where, $a_{i,j}$, $b_{i}$, $c$ and $d$ are all functions of $x_1, \dots, x_n$. Similarly, a general 1st order PDE in $n$ variables can be expressed as
\begin{equation}
    \sum_{i=1}^{n} \alpha_i (x_1, \dots, x_n) u_{x_i} + \beta (x_1, \dots, x_n) u = \gamma (x_1, \dots, x_n).
\end{equation}

A PDE that is not linear is called non-linear.

A PDE is called quasi-linear if it is linear in the highest order derivatives. For example, a first order quasi-linear PDE in two independent variables has the general form
\begin{equation}
    a(x,y,u) u_x + b(x,y,u) u_y = c(x,y,u).
\end{equation}

A PDE is called semi-linear if the coefficients of the highest order derivatives only contain independent variables. For example, the general form of a first order semi-linear PDE in two independent variables is
\begin{equation}
    a(x,y) u_x + b(x,y) u_y = c(x,y,u).
\end{equation}

\section{First Order Quasi-Linear PDEs}

\begin{nthm}
    Consider $\phi = \phi(x,y,z)$ and $\psi = \psi(x,y,z)$ such that $z = z(x,y)$. If $f(\phi, \psi) = 0$ for some arbitrary function $f$, then $\phi$ and $\psi$ satisfy the first order PDE
    \begin{equation}
        p \frac{\pd(\phi, \psi)}{\pd(y,z)} + q \frac{\pd(\phi, \psi)}{\pd(z,x)} = \frac{\pd(\phi, \psi)}{\pd(x,y)}
    \end{equation}
    where, $p = z_x$, $q = y_z$, and
    \begin{equation*}
        \frac{\pd(\phi, \psi)}{\pd(x,y)} \equiv
        \begin{vmatrix}
            \phi_x & \phi_y\\
            \psi_x & \psi_y
        \end{vmatrix}
    \end{equation*}
\end{nthm}
\begin{proof}
    Differentiating $f(\phi, \psi) = 0$ with respect to $x$ and $y$, separately, gives the following two equations
    \begin{align}
        f_{\phi} \paren*{\phi_x + p \phi_z} + f_{\psi} \paren*{\psi_x + p \psi_z} &= 0\\
        f_{\phi} \paren*{\phi_y + q \phi_z} + f_{\psi} \paren*{\psi_y + q \psi_z} &= 0
    \end{align}

    This can be written as a matrix equation
    \begin{equation}
        \begin{pmatrix}
        \phi_x + p \phi_z & \psi_x + p \psi_z\\
        \phi_y + q \phi_z & \psi_y + q \psi_z\\
        \end{pmatrix}
        \begin{pmatrix}
        f_{\phi} \\ f_{\psi}
        \end{pmatrix}
        =
        \begin{pmatrix}
        0 \\ 0
        \end{pmatrix}
    \end{equation}
    This has a non-trivial solution precisely when the determinant of the coefficient matrix vanishes. Several lines of algebraic manipulations lead to the required result
    \begin{equation}
    \begin{vmatrix}
        \phi_x + p \phi_z & \psi_x + p \psi_z\\
        \phi_y + q \phi_z & \psi_y + q \psi_z\\
    \end{vmatrix} = 0
    \implies
    p \frac{\pd(\phi, \psi)}{\pd(y,z)}
    + q \frac{\pd(\phi, \psi)}{\pd(z,x)}
    = \frac{\pd(\phi, \psi)}{\pd(x,y)}
    \end{equation}
\end{proof}

\begin{nthm}
    The general solution of a first order, quasi-linear PDE
    \begin{equation}
        a(x,y,u) u_x + b(x,y,u) u_y = c(x,y,u)
    \end{equation}
    is $f(\phi, \psi) = 0$, where $f$ is an arbitrary function and $\phi(x,y,u)=c_1$ and $\psi(x,y,u)=c_2$ are solutions of the characteristic equations
    \begin{equation}
        \frac{dx}{a(x,y,u)} = \frac{dy}{b(x,y,u)} = \frac{du}{c(x,y,u)}.
    \end{equation}
\end{nthm}
\begin{proof}
    The ratios in the characteristic equations can all be equated to a common parameter
    \begin{equation}
        \frac{dx}{a(x,y,u)} = \frac{dy}{b(x,y,u)} = \frac{du}{c(x,y,u)} = dt.
    \end{equation}
    As a result, we can write $dx = a dt$, $dy = b dt$ and $du = c dt$.

    Now, $\phi(x,y,u) = c_1$ gives
    \begin{equation}
        d\phi = \phi_x dx + \phi_y dy + \phi_u du = 0
        \implies a \phi_x + b \phi_y + c \phi_u = 0.
    \end{equation}
    Similarly,
    \begin{equation}
        d\psi = \psi_x dx + \psi_y dy + \psi_u du = 0
        \implies a \psi_x + b \psi_y + c \psi_u = 0.
    \end{equation}

    Simultaneously solving these two equations (for $a, b, c$) gives
    \begin{equation}
        \frac{a}{\frac{\pd(\phi, \psi)}{\pd(y,u)}} = \frac{b}{\frac{\pd(\phi, \psi)}{\pd(u,x)}} = \frac{c}{\frac{\pd(\phi, \psi)}{\pd(x,y)}} = \lambda.
    \end{equation}
    Equivalently,
    \begin{equation}
        \frac{\pd(\phi, \psi)}{\pd(y,u)} = \frac{a}{\lambda}, \quad
        \frac{\pd(\phi, \psi)}{\pd(u,x)} = \frac{b}{\lambda}, \quad
        \frac{\pd(\phi, \psi)}{\pd(x,y)} = \frac{c}{\lambda}.
    \end{equation}

    Now, since $f(\phi, \psi) = 0$, the previous theorem shows that $f = 0$ satisfies the PDE
    \begin{equation}
        p \frac{\pd(\phi, \psi)}{\pd(y,u)}
        + q \frac{\pd(\phi, \psi)}{\pd(u,x)}
        = \frac{\pd(\phi, \psi)}{\pd(x,y)},
    \end{equation}
    with $p = u_x$ and $q = u_y$. Using the expressions found above, we get
    \begin{equation}
        p \frac{\pd(\phi, \psi)}{\pd(y,u)}
        + q \frac{\pd(\phi, \psi)}{\pd(u,x)}
        = \frac{\pd(\phi, \psi)}{\pd(x,y)}
        \iff
        a p + b q = c.
    \end{equation}

    In other words, this $f(\phi,\psi) = 0$ satisfies the PDE $ap + bq = c$.
\end{proof}

% \subsection*{Worked Examples} [TBC]

\section{Canonical Form of the First Order Linear PDEs}
The method developed for the first order quasi-linear PDEs can also be applied to linear PDEs as a special cases where the coefficient functions take a particular form. However, when dealing only with linear first order PDEs, it is often more convenient to first transform them into a form that is easier to integrate. This is called the canonical (or standard) form.

As already noted, the general first order linear PDE in two variables is
\begin{equation}
    a(x,y) u_x + b(x,y) u_y + c(x,y) u = d(x,y).
\end{equation}

We introduce new variables $\xi = \xi(x,y)$ and $\eta = \eta(x,y)$ such that the Jacobian of this transformation is non-zero. That is
\begin{equation}
    J = \abs*{\frac{\pd(\xi, \eta)}{\pd(x,y)}} =
    \begin{vmatrix}
        \xi_x & \xi_y \\ \eta_x & \eta_y
    \end{vmatrix}
    \neq 0.
\end{equation}
Then, the chain rule gives,
\begin{equation}
    u_x = u_\xi \xi_x + u_\eta \eta_x,
    \qquad
    u_y = u_\xi \xi_y + u_\eta \eta_y.
\end{equation}
This converts the original PDE into
\begin{equation}
    A u_\xi + B u_\eta + cu = d,
\end{equation}
with $A = a \xi_x + b \xi_y$ and $B = a \eta_x + b \eta_y$.

Out of all the possible change of variables, we seek the ones where $A$ vanishes. In other words, we pick $\xi = \xi(x,y)$ such that it satisfies the (simpler) first order linear PDE
\begin{equation}
    a \xi_x + b \xi_y = 0
\end{equation}

We can't also require $B = 0$ simultaneously, otherwise $\xi$ and $\eta$ will no longer be independent (as they will follow from the same PDE), and their Jacobian will vanish.

Overall, if we can find a suitable $\xi = \xi(x,y)$ then we have transformed the original first order linear PDE into its canonical form
\begin{equation}
    a u_x + b u_y + c u = d
    \quad\to\quad B u_\eta + cu = d
    \quad\to\quad u_\eta + \alpha(\xi, \eta) u = \beta(\xi, \eta).
\end{equation}
Here, $\alpha = c/B$ and $\beta = d/B$.

% \subsection*{Worked Examples} [TBC]
\begin{negg}
    Reduce $u_x - u_y = u$ to its canonical form, and obtain its general solution.

    Comparing this with the general form of the quasi-linear equation, we note that $a = 1$, $b = -1$ and $c = u$.

    We start by finding a suitable $\xi$ from $a \xi_x + b \xi_y = 0$. The corresponding characteristic equations are
    \begin{equation*}
        \frac{dx}{1} = \frac{dy}{-1} = \frac{d\xi}{0}.
    \end{equation*}
    For these, $d\xi = 0$ immediately gives $\xi = c_1$ as one characteristic curve. For the second characteristic curve, we solve the first two ratios to obtain $y = -x + c_2$, or $x + y = c_2$. So, a particular solution for $\xi$ is, $\xi = x+y$.

    (Here, the general solution would have been $f(\phi, x+y) = 0$. We, firstly, re-write this as $\xi = g(x+y)$, and then pick the simplest non-trivial case $g(x+y) = x+y$ as a particular choice of the change of variables for $\xi$.)

    We pick a simple (but independent) expression $\eta = y$.

    Using $\xi = x+y$ and $\eta = y$, we find that $u_x = u_\xi$ and $u_y = u_\xi + u_\eta$. So,
    \begin{equation}
        u_x - u_y = u
        \implies
        u_\eta = u.
    \end{equation}

    This integrates to $u = f(\xi) e^{-\eta}$, where $f$ is an arbitrary function. Converting back into $x$ and $y$, we obtain
    \begin{equation}
        u(x, y) = f(x+y) e^{-y}.
    \end{equation}
\end{negg}

\section{Geometry of the First Order Quasilinear PDEs}
Consider a general first order quasilinear PDE in two variables
\begin{equation}
    \alpha(x, y, u) u_x + \beta(x, y, u) u_y - c(x, y, u) = 0
\end{equation}
Its solution is the surface $u = u(x,y)$. We can re-write this equation of a surface as
\begin{equation}
    f(x, y, u) \equiv u(x,y) - u = 0.
\end{equation}
Noting that the gradient of this new function $f$ is $\nabla f = \paren{ u_x, u_y, -1 }$, we can express the given PDE as dot product
\begin{equation}
    \paren{a, b, c} \cdot \paren{ u_x, u_y, -1 } = 0.
\end{equation}

The gradient of $f$ represents a normal vector to the surface $f$ at the point $(x, y, u)$. Therefore, the previous equation states that the solution surface $u = u(x,y)$ is such that the vector $\paren{a, b, c}$ always lies in its tangent plane at $(x, y, u)$.

Suppose we have a parametrised curve $\paren{x(t), y(t), u(t)}$ lying on the surface $f(x,y,u) = 0$ at the point $\paren{x,y,u}$. Then, its tangent vector $\paren{dx/dt, dy/dt, du/dt}$ is again perpendicular to $\nabla f$ and lies in the tangent plane. We can therefore, equate $\paren{dx/dt, dy/dt, du/dt}$ with $\paren{a, b, c}$ to get a set of ODEs
\begin{equation}
    \frac{dx}{dt} = a(x,y,u),
    \frac{dy}{dt} = b(x,y,u),
    \frac{du}{dt} = c(x,y,u).
\end{equation}
Equivalently,
\begin{equation}
    \frac{dx}{a} = \frac{dy}{b} = \frac{du}{c}.
\end{equation}
These are called the characteristic equations, and their solutions are called characteristic curves.

We find that these lead to two families of surfaces
\begin{equation}
    \phi(x,y,u) = c_1
    \qquad\text{and}\qquad
    \psi(x,y,u) = c_2.
\end{equation}
Their intersection leads to a two-parameter family of curves $g(\phi, \psi) = 0$ which we saw was the general solution to the given quasilinear PDE.

\section{Separation of Variables}
Some PDEs admit solutions $u(x,y)$ that can be separated into independent functions of $x$ and $y$. For example, we can have
\begin{equation}
    u(x,y) = X(x) Y(y)
    \quad\text{or}\quad
    u(x,y) = X(x) + Y(y)
\end{equation}
among other choices. (We will only focus on these two choices.)

Substituting such an ansatz into the given PDE, we try to move all the $x$ and $y$-dependent terms to opposite sides of the equals signs. This step requires careful algebraic manipulations. Two functions of two different variables can only be equal to each other for all values of those variables if and only if they are equal to the same constant.
\begin{equation}
    f(x) = g(y), \forall x,y
    \implies
    f(x) = \lambda, g(x) = \lambda
\end{equation}

\begin{negg}
    Consider the equation $y^2 u_x^2 + x^2 u_y^2 = \paren{xyu}^2$.

    We will try to solve it using the separation of variables with $u(x,y) = f(x)g(y) \neq 0$. Substituting this form of $u(x,y)$ into the PDE gives
    \begin{equation}
        \paren*{y f'(x) g(y)}^2 + \paren*{x f(x) g'(y)}^2 = \paren{xy f(x) g(y)}^2
    \end{equation}
    Dividing throughout by $x^2 y^2 f(x)^2 g(y)^2$ and rearranging, gives
    \begin{equation}
        \frac{1}{x^2}\paren*{\frac{f'(x)}{f(x)}}^2
        = 1 - \frac{1}{y^2} \paren*{\frac{g'(y)}{g(y)}} = \lambda^2
    \end{equation}
    for some constant $\lambda^2$; the square indicates that this constant must be positive because the LHS is always positive.

    This leads to a set of ODES
    \begin{equation}
        f'(x) = x\lambda f(x)
        \quad\text{and}\quad
        g'(y) = y g(y) \sqrt{1 - \lambda^2}
    \end{equation}
    whose solution is
    \begin{equation}
        f(x) = A \exp\paren*{ \frac{\lambda}{2} x^2}
        \quad\text{and}\quad
        g(y) = B \exp\paren*{ \frac{1}{2} y^2 \sqrt{1 - \lambda^2}}.
    \end{equation}
    with arbitrary constants $A, B$.

    As a result, the full solution of the PDE becomes
    \begin{equation}
        u(x,y) = C \exp\paren*{ \frac{\lambda}{2}x^2 + \frac{1}{2}y^2 \sqrt{1 - \lambda^2} },
    \end{equation}
    where $C$ is again an arbitray constant.
\end{negg}

\begin{negg}
    We will solve the first order non-linear PDE $u_x^2 + u_y + x^2 = 0$ with the ansatz $u(x,y) = f(x) + g(y)$.

    The substitution into the PDE gives
    \begin{equation}
        \paren*{f'(x)}^2 + g'(y) + x^2 = 0
        \implies
        \paren*{f'(x)}^2 + x^2 = - g'(y) = \lambda^2.
    \end{equation}
    Solving these separate ODEs gives
    \begin{equation}
        f(x) = A + \frac{1}{2} \lambda^2 \paren*{ \asin\paren*{\frac{x}{\lambda}} + \frac{x}{\lambda}\sqrt{1 - \frac{x^2}{\lambda^2}} }
        \quad\text{and}\quad
        g(y) = -\lambda^2 y + B.
    \end{equation}
    Therefore, $u(x,y) = \frac{1}{2} \lambda^2 \paren*{ \asin\paren*{\frac{x}{\lambda}} + \frac{x}{\lambda}\sqrt{1 - \frac{x^2}{\lambda^2}} -2y }  + C$.
\end{negg}

\section{Classification of Second Order Linear Equations}
In this section we shall focus on classifying second order linear PDEs with two independent variables $x$ and $y$. The most general such equation is
\begin{equation}
    A u_{xx} + B u_{xy} + C u_{yy} + D u_x + E u_y + F u = G
\end{equation}
where the coefficients $A, \dots, G$ are all functions of $x$ and $y$ only. We require the dependent variable $u = u(x,y)$ and these coefficient functions $A, \dots, G$ to be twice continuously differentiable in some domain $D \subseteq \R^2$.

The above equation is reminiscent of the general quadratic equation for conic sections from analytic geometry. A conic section is classified as either elliptic, parabolic or hyperbolic based on the value of its determinant $B^2 - 4AC$. We shall use this similarity, to classify the second order linear PDEs into three similarly named classes: elliptic, parabolic or hyperbolic at a given point $(x_0, y_0)$ determined by the sign of
\begin{equation}
    B^2(x_0, y_0) - 4 A(x_0, y_0) B(x_0, y_0).
\end{equation}

We say that a second order linear PDE is elliptic, parabolic or hyperbolic at $(x_0, y_0)$ if
\begin{equation}
    B^2(x_0, y_0) - 4 A(x_0, y_0) B(x_0, y_0).
\end{equation}
is negative, zero or positive, respectively.

If this condition is true at all points in $D$, then the equation is said to be elliptic, parabolic or hyperbolic in the entire domain.

In the case of two variables, we can always find a transformation that reduces given second order linear PDE into its corresponding canonical form. (This is not in general possible for the case of more than two independent variables.)

To obtain a canonical form for the given PDE in some domain $D$, we make a change of variables $\xi = \xi(x, y)$ and $\eta = \eta(x, y)$ with a non-vanishing Jacobian in $D$.
\begin{equation}
    J = \begin{vmatrix} \xi_x & \xi_y \\ \eta_x & \eta_y \end{vmatrix}.
\end{equation}
Under this transformation, we obtain
\begin{align*}
    u_x    &= u_\xi \xi_x + u_\eta \eta_x\\
    u_y    &= u_\xi \xi_y + u_\eta \eta_y\\
    u_{xx} &= u_{\xi\xi} \xi_x^2 + 2u_{\xi\eta} \xi_x \eta_x + u_{\eta\eta} \eta_x^2 + u_\xi \xi_{xx} + u_\eta \eta_{xx}\\
    u_{xy} &= u_{\xi\xi} \xi_x \xi_y + u_{\xi\eta} \paren*{\xi_x \eta_y + \xi_y \eta_x} + u_{\eta\eta} \eta_x \eta_y + u_\xi \xi_{xy} + u_\eta \eta_{xy}\\
    u_{yy} &= u_{\xi\xi} \xi_y^2 + 2u_{\xi\eta} \xi_y \eta_y + u_{\eta\eta} \eta_x^2 + u_\xi \xi_{yy} + u_\eta \eta_{yy}.
\end{align*}
This allows us to rewrite the original PDE as
\begin{equation}
    A^{*} u_{\xi\xi} + B^{*} u_{\xi\eta} + C^{*} u_{\eta\eta} + D^{*} u_\xi + E^{*} u_\eta + F u = G
    \label{eq:2nd-transformed-xi-eta-full}
\end{equation}
where
\begin{align*}
    A^{*} &= A \xi_x^2 + B \xi_x \xi_y + C \xi_y^2\\
    B^{*} &= 2A\xi_x \eta_x + B \paren*{\xi_x \eta_y + \xi_y \eta_x} + 2C \xi_y \eta_y\\
    C^{*} &= A \eta_x^2 + B \eta_x \eta_y + C \eta_y^2\\
    D^{*} &= A \xi_{xx} + B \xi_{xy} + C \xi_{yy} + D \xi_{x} + E \xi_{y}\\
    E^{*} &= A \eta_{xx} + B \eta_{xy} + C \eta_{yy} + D \eta_{x} + E \eta_{y}.
\end{align*}
We can also write this more compactly as
\begin{equation}
    A^{*} u_{\xi\xi} + B^{*} u_{\xi\eta} + C^{*} u_{\eta\eta} = H^{*}\paren*{\xi, \eta, u, u_\xi, u_\eta}
    \label{eq:2nd-transformed-xi-eta}
\end{equation}

Next, we restrict ourselves to only those $\xi(x,y)$ and $\eta(x,y)$ which leads to $A^* = 0$. That is
\begin{equation}
    A \xi_x^2 + B \xi_x \xi_y + C \xi_y^2 = 0.
\end{equation}
However, we note that $C^* = 0$ has the same form. So, if we can find two independent solutions of $A^* = 0$, then one of them can be labelled as $\eta$, leading to $C^* = 0$. Therefore, we consider the more general PDE of this form
\begin{equation}
    A \zeta_x^2 + B \zeta_x \zeta_y + C \zeta_y^2
\end{equation}
We seek its solution as characteristic curves of the form $\zeta(x,y) = c$. This gives
\begin{equation}
    d\zeta = \zeta_x \,dx + \zeta_y \,dy = 0
    \implies
    \frac{\zeta_x}{\zeta_y} = - \frac{dy}{dx}.
\end{equation}
Consequently,
\begin{align}
    A \zeta_x^2 + B \zeta_x \zeta_y + C \zeta_y^2 = 0
    &\implies
    A \paren*{\frac{\zeta_x}{\zeta_y}}^2 + B \paren*{\frac{\zeta_x}{\zeta_y}} + C = 0\\
    &\implies
    A \paren*{\frac{dy}{dx}}^2 - B \paren*{\frac{dy}{dx}} + C = 0.
\end{align}
This is a quadratic equation in $dy/dx$, so the quadratic formula gives
\begin{equation}
    \frac{dy}{dx} = \frac{B \pm \sqrt{B^2 - 4AC}}{2A}.
    \label{eq:2nd-char}
\end{equation}
Recall that $A, B$ and $C$ are in general functions of $x$ and $y$ and therefore, we cannot reduce this equation further at this stage.

The solution $y(x)$ or equivalently $\zeta(x,y) = c$ will now depend on the nature of the discriminant $B^2 - 4AC$. This will form the basis of our classification of the second order linear PDEs.

\subsection{Hyperbolic PDEs \texorpdfstring{($B^2 - 4AC > 0$)}{B2 - 4AC > 0}}
When $B^2 - 4AC > 0$ the PDE is called hyperbolic and equation~\eqref{eq:2nd-char} has two distinct solutions $dy/dx = T_{1,2}(x,y)$. Solving this first order ODE then gives two distinct solutions, which we label as $\xi(x,y) = c_1$ and $\eta(x,y) = c_2$.

Tracing our steps back, we conclude that if $dy/dx$ solves equation~\eqref{eq:2nd-char}, then the resulting characteristics $\zeta(x,y) = c$ satisfy a PDE of the form $A \zeta_x^2 + B \zeta_x \zeta_y + C \zeta_y^2 = 0$. Consequently, the $\xi(x,y) = c_1$ and $\eta(x,y) = c_2$ found here should satisfy
\begin{equation}
    A \xi_x^2 + B \xi_x \xi_y + C \xi_y^2 = 0
    \quad\text{and}\quad
    A \eta_x^2 + B \eta_x \eta_y + C \eta_y^2 = 0.
\end{equation}
In other words, when $B^2 - 4AC > 0$ then we can find suitable $\xi$ and $\eta$ which simultaneously give $A^* = C^* = 0$, reducing equation~\eqref{eq:2nd-transformed-xi-eta} to
\begin{equation}
    u_{\xi\eta} = H_{h}^{*}\paren*{\xi, \eta, u, u_\xi, u_\eta}
    \label{eq:canonical-hyperbolic}
\end{equation}
where $H_{h}^{*} \equiv H^{*} / B^{*}$. Equation~\eqref{eq:canonical-hyperbolic} is the canonical form of a hyperbolic PDE.

\subsection{Parabolic PDEs \texorpdfstring{($B^2 - 4AC = 0$)}{B2 - 4AC = 0}}
When $B^2 - 4AC = 0$ the PDE is called parabolic and equation~\eqref{eq:2nd-char} has only one solution $dy/dx = T(x,y)$. Solving this first order ODE then gives a single solution, which we label as $\xi(x,y) = c_1$. No restriction has been obtained for $\eta = \eta(x,y)$. So, we obtain that $A^{*} = 0$; and $C^{*} \neq 0$.

Now, since $B^2 = 4AC$, we can write
\begin{equation}
    A^{*}
    = A \xi_x^2 + B \xi_x \xi_y + C \xi_y^2
    = \paren*{ \sqrt{A} \xi_x + \sqrt{C} \xi_y }^2,
\end{equation}
which gives $\sqrt{A} \xi_x + \sqrt{C} \xi_y = 0$ because $A^{*} = 0$. Therefore,
\begin{align}
    B^{*}
    &= 2A\xi_x \eta_x + B \paren*{\xi_x \eta_y + \xi_y \eta_x} + 2C \xi_y \eta_y\\
    &= 2 \paren*{ \sqrt{A} \xi_x + \sqrt{C} \xi_y } \paren*{ \sqrt{A} \eta_x + \sqrt{C} \eta_y }
    = 0
\end{align}
for all arbitrary $\eta(x,y)$. Consequently, both $A^*$ and $B^*$ vanish for parabolic PDES.

Overall, when $B^2 - 4AC = 0$ then we can find $\xi = \xi(x,y)$ by solving~\eqref{eq:2nd-char} (and a suitable, simple $\eta$ is chosen arbitrarily) which leads to $A^* = B^* = 0$, reducing equation~\eqref{eq:2nd-transformed-xi-eta} to
\begin{equation}
    u_{\eta\eta} = H_{p}^{*}\paren*{\xi, \eta, u, u_\xi, u_\eta}
    \label{eq:canonical-parabolic}
\end{equation}
where $H_{p}^{*} \equiv H^{*} / C^{*}$. Equation~\eqref{eq:canonical-parabolic} is the canonical form of a parabolic PDE.

\subsection{Elliptic PDEs \texorpdfstring{($B^2 - 4AC < 0$)}{B2 - 4AC < 0}}
In this case, the PDE is known as an elliptic PDE. Here, the characteristic equation~\eqref{eq:2nd-char} gives rise to two complex conjugate solutions. We can, therefore, decompose the resulting $\xi$ and $\eta$ in terms of real valued variables $\alpha$ and $\beta$ as $\xi = \alpha + i\beta, \quad \eta = \alpha - i \beta$. Equivalently,
\begin{equation}
    \alpha = \frac{1}{2} \paren*{\xi + \eta},
    \quad
    \beta = \frac{1}{2i} \paren*{\xi - \eta}.
\end{equation}
This can be viewed as a further change of variables on the PDE~\eqref{eq:2nd-transformed-xi-eta} leading to
\begin{equation}
    A^{**} u_{\alpha\alpha} + B^{**} u_{\alpha\beta} + C^{**} u_{\beta\beta} = H^{**}\paren*{\alpha, \beta, u, u_\alpha, u_\beta}
    \label{eq:2nd-transformed-alpha-beta}
\end{equation}
where the coefficients $A^{**}, \dots, H^{**}$ have the same form as $A^{*}, \dots, H^{*}$.

Now, writing $A^{*}\paren*{\xi} = 0$ in terms of $\alpha$ and $\beta$ gives
\begin{equation}
    EQQ
\end{equation}
or equivalently, $\paren*{A^{**} - C^{**}} + i B^{**} = 0$. Similarly, $C^{*} = 0$ gives $\paren*{A^{**} - C^{**}} - i B^{**} = 0$. For these equations to hold, we must have $A^{**} = C^{**}$ and $B^{**} = 0$.

Consequently, equation~\eqref{eq:2nd-transformed-alpha-beta} becomes
\begin{equation}
    u_{\alpha\alpha} + u_{\beta\beta} = H_{e}^{**} \paren*{\alpha, \beta, u, u_\alpha, u_\beta}
    \label{eq:canonical-elliptic}
\end{equation}
with $H_{e}^{**} = H^{**} / A^{**}$.

Overall, when $B^2 - 4AC < 0$ we first find $\xi(x,y)$ and $\eta(x,y)$ through the characteristic equation~\eqref{eq:2nd-char}. Then we set $\alpha(x,y) = \Re \xi$ and $\beta(x,y) = \Im \xi$ (using $\eta$ gives the same final result). Using $\alpha$ and $\beta$ are the change of variables on the original equation then leads to~\eqref{eq:canonical-elliptic}. This is the canonical form of the Elliptic PDEs.

\begin{negg}
    Consider the equation
    \begin{equation}
        y^2 u_{xx} - x^2 u_{yy} = 0.
        \label{eq:example-hyp}
    \end{equation}
    Here, $A = y^2$, $B = 0$ and $C = -x^2$. This is a hyperbolic equation in the region $xy \neq 0$ because $B^2 - 4AC = 4x^2 y^2 > 0$. The associated characteristic equation is
    \begin{equation}
        \frac{dy}{dx} = \frac{B \pm \sqrt{B^2 - 4AC}}{2A} = \pm\frac{x}{y}
    \end{equation}
    leading to the integral curves $y^2 + x^2 = c_1$ and $y^2 - x^2 = c_2$. We set $\xi = y^2 + x^2$ and $\eta = y^2 - x^2$. Then,
    \begin{gather}
        u_{xx}
        = 4 x^2 u_{\xi\xi} - 8 x^2 u_{\xi\eta} + 4 x^2 u_{\eta\eta} + 2 u_\xi - 2 u_\eta\\
        u_{yy}
        = 4 y^2 u_{\xi\xi} + 8 y^2 u_{\xi\eta} + 4 y^2 u_{\eta\eta} + 2 u_\xi + 2 u_\eta.
    \end{gather}
    As a result, equation~\eqref{eq:example-hyp} transforms into $-16 x^2 y^2 u_{\xi\eta} + 2 (y^2 - x^2) u_{\xi} - 2 (y^2 - x^2) u_{\xi} = 0$, where we eliminate $\xi$ and $\eta$ to obtain the canonical form of equation~\eqref{eq:example-hyp}
    \begin{equation}
        u_{\xi\eta} = \frac{\eta}{2 \paren*{\xi^2 - \eta^2}} u_{\xi} - \frac{\xi}{2 \paren*{\xi^2 - \eta^2}} u_{\xi}.
    \end{equation}

    \textbf{Alternative:} Instead of computing $u_{xx}$ and $u_{yy}$ we could have computed the non-vanishing coefficients $B^{*}, D^{*}, E^{*}$ appearing in \eqref{eq:2nd-transformed-xi-eta-full}. This leads to
    \begin{gather*}
        B^{*}
        = 2A\xi_x \eta_x + B \paren*{\xi_x \eta_y + \xi_y \eta_x} + 2C \xi_y \eta_y
        = - 8 x^2 y^2 - 8 x^2 y^2
        = - 16 x^2 y^2
        = 4 \paren*{\xi^2 - \eta^2}\\
        D^{*}
        = A \xi_{xx} + B \xi_{xy} + C \xi_{yy} + D \xi_{x} + E \xi_{y}
        = 2 y^2 - 2 x^2
        = 2 \eta\\
        E^{*}
        = A \eta_{xx} + B \eta_{xy} + C \eta_{yy} + D \eta_{x} + E \eta_{y}
        = - 2 \xi.
    \end{gather*}
    which results in the same transformed equation.
\end{negg}

\begin{negg}
    The second order linear partial differential equation
    \begin{equation}
        x^2 u_{xx} + 2xy u_{xy} + y^2 u_{yy} = 0
    \end{equation}
    is parabolic for all values of $x$ and $y$ because it satisfies $B^2 - 4AC = 4x^2 y^2 - 4 x^2 y^2 = 0$. Its associated characteristic equation is $dy/dx = y/x$, which integrates to $y/x = c$. We set $\xi = y/x$ and arbitrarily take $\eta = y$.

    The coefficients of the transformed PDE are then
    \begin{equation}
        C^{*} = y^2,
        \quad
        D^{*} = \frac{2y}{x} - \frac{2y}{x} = 0,
        \quad
        E^{*} = 0,
    \end{equation}
    resulting in $y^2 u_{\eta\eta} = 0$, or simply $u_{\eta\eta} = 0$ for $y \neq 0$.
\end{negg}

\begin{negg}
    The PDE
    \begin{equation}
        u_{xx} + x^2 u_{yy} = 0
    \end{equation}
    is elliptic for $x \neq 0$. The characteristic equations $dy/dx = \pm i x$ integrate to $2y \pm ix^2 = c_{\pm}$. We set $\xi = 2y + ix^2$ and $\eta = 2y - ix^2$. This corresponds to $\alpha = \Re\xi = 2y$ and $\beta = \Im\xi = x^2$.

    As a result, the coefficients of the transformed PDE are
    \begin{equation}
        A^{*} = \alpha_x^2 + x^2 \alpha_y^2 = 4 x^2,
        \quad
        D^{*} = \alpha_{xx} + x^2 \alpha_{yy} = 0,
        \quad
        E^{*} = \beta_{xx} + x^2 \beta_{yy} = 2.
    \end{equation}
    The transformed equation is therefore, $4 x^2 u_{\alpha\alpha} + 4 x^2 u_{\beta\beta} + 2 u_{\beta} = 0$. After expressing $x$ and $y$ in terms of $\alpha$ and $\beta$ this takes the canonical form
    \begin{equation}
        u_{\alpha\alpha} + u_{\beta\beta} = -\frac{1}{2\beta} u_{\beta}.
    \end{equation}
\end{negg}

\section{Cauchy Problem and the Wave Equation}
In order to obtain a particular solution on a given PDE we need to prescribe some additional conditions on the solution $u = u(x,t)$. In the case of ODEs, the initial-value problems provide one way of specifying this data. For example, for a second order ODE we specify the value of the unknown function and its first derivative at the same point in the domain. This notion can be generalise to PDEs as follows.

Consider a PDE in two independent variables where we are solving for the unknown function $u = (x,t)$ with $x \in \R$ and $t \geq t_0$. If we specify the conditions
\begin{equation}
    u(x, t_0) = u_0 (x)
    \quad\text{and}\quad
    u_t (x, t_0) = v_0 (x)
\end{equation}
then the resulting system of equations is called a Cauchy problem. These initial conditions don't have to be given along the axis $t = t_0$; instead they can also be specified along a suitable curve $C$ in the domain.

\subsection{Homogenous Wave Equation}
Let $u = u(x,t)$ be a function satisfying
\begin{equation}
    u_{tt} - c^2 u_{xx} = 0
    \label{eq:wave-eqn}
\end{equation}
for a constant $c \in \R$, over the domain $x \in \R$ and $t \geq 0$. This is called the homogenous wave equation (in one spatial dimension) over the full real line.

\subsection{Homogenous Wave Equation on an Infinite Spatial Domain}
The associated Cauchy problem requires that the $u$ must satisfy the initial conditions
\begin{equation}
    u(x, 0) = f(x)
    \quad\text{and}\quad
    u_t (x, 0) = g(x)
    \label{eq:wave-initial-infinite}
\end{equation}
for suitably chosen functions $f$ and $g$.

To solve this problem, we start by transforming the wave equation~\eqref{eq:wave-eqn} into its canonical form. Here, $A = 1$, $B = 0$ and $C = -c^2$. So, $B^2 - 4AC = 4c^2 > 0$ for all $x$ and $t$. Therefore, this is a hyperbolic PDE with the characteristics
\begin{equation}
    \frac{dx}{dt} = \pm c
    \implies
    x \pm ct = \text{constant}.
\end{equation}
Set $\xi = x + ct$ and $\eta = x - ct$. Then, $B^{*} = 2 + 2c^4$ and the transformed PDE is $u_{\xi\eta} = 0$. This can easily be integrated to obtain a general solution
\begin{equation}
    u(\xi, \eta) = \varphi(\xi) + \psi(\eta),
\end{equation}
with $\xi, \eta \in \R$, or equivalently,
\begin{equation}
    u(x, t) = \varphi(x + ct) + \psi(x - ct).
    \label{eq:wave-gen-soln}
\end{equation}

Next, we impose the initial conditions: $u(x, 0) = f(x)$ gives $\varphi(x) + \psi(x) = f(x)$ and $u_t (x, 0) = g(x)$ gives $c\varphi'(x) - c\psi'(x) = g(x)$. Integrating the last equation with respect to $x$ leads to
 \begin{equation}
    \varphi(x) - \psi(x) = \frac{1}{c} \int_{x_0}^{x} g(x) \,dx + K.
\end{equation}
where $x_0$ and $K$ are arbitrary constants. Therefore,
\begin{gather}
    \varphi(x) = \frac{1}{2} f(x) + \frac{1}{2c} \int_{x_0}^{x} g(x) \,dx + \frac{K}{2}, \label{eq:wave-phi}\\
    \psi(x) = \frac{1}{2} f(x) - \frac{1}{2c} \int_{x_0}^{x} g(x) \,dx - \frac{K}{2} \label{eq:wave-psi}.
\end{gather}
Overall, the general solution~\eqref{eq:wave-gen-soln} becomes
\begin{equation}
    u(x, t)
    = \frac{1}{2} \paren*{f\paren*{x + ct} + f\paren*{x - ct}}
    + \frac{1}{2c} \int_{x + ct}^{x - ct} g(x) \,dx.
    \label{eq:wave-soln-infinite}
\end{equation}
for the initial conditions~\eqref{eq:wave-initial-infinite}. This is also called the d'Alembert's solution.

\subsection{Homogenous Wave Equation on a Semi-Infinite Spatial Domain}
Now we consdier the same wave equation~\eqref{eq:wave-eqn} over a semi infinite spatial domain $x \in [0, \infty)$. In this case we also have a boundary condition at $x=0$. For example, suppose we require $u(x,t)$ to be fixed at $x=0$. This situtaion can be described as
\begin{equation}
    u(x, 0) = f(x)
    \quad\text{and}\quad
    u_t (x, 0) = g(x)
    \quad\text{and}\quad
    u(0, t) = 0
    \label{eq:wave-initial-semiinfinite}
\end{equation}
for all $x \in [0, \infty)$ and $t \geq 0$.

To analyse this problem, we identify two cases: either $x - ct \geq 0$, in that case $x \geq 0$ and we simply obtain the d'Alembert's solution~\eqref{eq:wave-soln-infinite}. Or, $x - ct < 0$. Then $x < 0$ and the boundary condition at $x = 0$ becomes important and we can no longer directly use d'Alembert's solution.

For $x - ct < 0$, we start by using the boundary condition $u(0, t) = 0$ in equation~\eqref{eq:wave-gen-soln} to obtain $\varphi(ct) + \psi(-ct) = 0$, or equivalently, $\psi(\theta) = - \varphi(-\theta)$. Therefore, equation~\eqref{eq:wave-gen-soln} gives
\begin{equation}
    u(x, t) = \varphi\paren*{x + ct} - \varphi\paren*{-\paren*{x - ct}}.
\end{equation}
We obtained equations~\eqref{eq:wave-phi}-\eqref{eq:wave-psi} using the initial conditions, so they still remain valid. Using these expressions in the previous equation then gives
\begin{equation}
    u(x, t)
    = \frac{1}{2} \paren[\bigg]{f\paren*{x + ct} - f\paren*{-\paren*{x - ct}}}
    + \frac{1}{2c} \int_{-\paren*{x - ct}}^{x + ct} g(x) \,dx.
    \label{eq:wave-soln-semiinfinite}
\end{equation}

% [TBC]
% Alternatively, we can require $u(x,t)$ to be free at $x=0$. This corresponds to $u_x(0,t) = 0$ for all $t \geq 0$. Collectively, the initial-boundary conditions become
% \begin{equation}
%     u(x, 0) = f(x)
%     \quad\text{and}\quad
%     u_t (x, 0) = g(x)
%     \quad\text{and}\quad
%     u_x (0, t) = 0
% \end{equation}
% for all $x \in [0, \infty)$ and $t \geq 0$. A similar analysis shows that now the solution is

% SOMETHING SOMETHING.

% \subsection{Homogenous Wave Equation on a Finite Spatial Domain}
% Suppose now restrict the spatial coordinate to $x \in [0, \ell]$. The corresponding initial-boundary conditions where both ends are fixed are
% \begin{equation}
%     u(x, 0) = f(x)
%     \quad\text{and}\quad
%     u_t (x, 0) = g(x)
%     \quad\text{and}\quad
%     u(0, t) = u(\ell, t) = 0.
%     \label{eq:wave-initial-finite}
% \end{equation}

% SOMETHING SOMETHING.

\section{Method of Separation of Variables}
\subsection{The Vibrating String Problem (Homogenous Case)}
Consider an inelastic string of length $\ell$. We fix its ends at $x = 0$ and $x = \ell$. Let $u = u(x,t)$ describes the profile of the string at time $t$ after it has been given an initial displacement $f(x)$ and an initial velocity $g(x)$. The shape of the string, $u(x,t)$, then evolves according to the wave equation along with the prescribed initial and boundary data.
\begin{equation}
\begin{gathered}
    \utt - c^2 \uxx = 0, \quad x \in [0, \ell], \quad t \geq 0\\
    u(x,0) = f(x), \quad x \in [0, \ell]\\
    u_t(x,0) = g(x), \quad x \in [0, \ell]\\
    u(0,t) = u(\ell,t) = 0, \quad t \geq 0.
\end{gathered}
\label{eq:vibrating-string-problem-h}
\end{equation}
Here, $c$ is a constant, called the wave speed. Physically, it is determined by the tension in the string.

We note that this is a homogenous PDE, and that the boundary conditions are also homogenous. Such problems can sometimes be handled by the method of separation of variables. Using this method, we look for a non-trivial solution $u(x,t)$ of the form $u(x,t) = X(x) T(t)$. Since $u$ is assumed to be non-trivial, we must \emph{not} have $X(x) \equiv 0$ or $T(t) \equiv 0$.

In terms of this ansatz, the PDE becomes
\begin{equation}
    X(x) \ddot{T}(t) - c^2 X''(x) T(t) = 0, \quad x \in [0, \ell], \quad t \geq 0,
\end{equation}
and the boundary conditions take the form $X(0) = X(\ell) = 0$ for all $t \geq 0$.

We can now separate the differential equation as
\begin{equation}
    X(x) \ddot{T}(t) - c^2 X''(x) T(t) = 0
    \implies
    \frac{X''(x)}{X(x)} = \frac{1}{c^2} \frac{\ddot{T}(t)}{T(t)} = \lambda.
\end{equation}
In the last step we used the fact that the LHS is a function of $x$ while the RHS is only a function of $y$, so, they are equal to some common constant $\lambda$. As a result, the given PDE has been decoupled into two ODEs
\begin{equation}
    X'' - \lambda X = 0
    \quad\text{and}\quad
    \ddot{T} - c^2 \lambda T = 0.
\end{equation}
These ODEs lead to different solutions based on the values of $\lambda$.

For $\lambda = 0$, we have $X'' = 0$ which gives $X(x) = c_1 x + c_2$ for some constants $c_1, c_2$. Now, $X(0)=X(\ell)=0$ implies $c_1 = c_2 = 0$. Therefore, $X(x) \equiv 0$. So, the case $\lambda = 0$ is not valid because it results in the trivial solution $u(x,t) = 0$ for all $x \in [0, \ell]$ and $t \geq 0$, while we are only seeking non-trivial solutions.

If $\lambda > 0$, then $X'' - \lambda X = 0$ implies $X(x) = c_1 e^{\sqrt{\lambda}x} + c_2 e^{-\sqrt{\lambda}x}$, which along with the boundary conditions $X(0) = X(\ell) = 0$ leads to the system of linear equations
\begin{align}
    c_1 + c_2 &= 0 \\
    c_1 e^{\sqrt{\lambda}\ell} + c_2 e^{-\sqrt{\lambda}\ell} &= 0.
\end{align}
Here, the coefficient matrix is non-singular, so we must have $c_1 = c_2 = 0$. Therefore, $X(x) \equiv 0$ and we again get the trivial solution for $u(x,t)$. So, we also ignore $\lambda > 0$.

Lastly, if $\lambda < 0$, then we can write it as $\lambda = - \alpha^2$. Now, $X'' - \lambda X = 0$ becomes $X'' + \alpha^2 X = 0$ and leads to the solution
\begin{equation}
    X(x) = c_1 \cos\paren*{\alpha x} + c_2 \sin\paren*{\alpha x}.
\end{equation}
Using $X(0) = 0$ implies $c_1 = 0$, giving $X(x) = c_2 \sin\paren*{\alpha x}$.

The other boundary condition $X(\ell) = 0$ corresponds to $c_2 \sin\paren{\alpha \ell} = 0$. If we take $c_2 = 0$ then again we obtain the trivial solution $X(x) \equiv 0$. So, instead, we require $\sin\paren{\alpha \ell} = 0$. This is equivalent to $\alpha \ell = n\pi$, or $\alpha = n\pi / \ell$. This shows that the allowed solutions for $X(x)$ can be labelled by $n$,
\begin{equation}
    X_n (x) = c_{2n} \sin\paren*{\frac{n \pi x}{\ell}}
    \quad n = 1, 2, 3, \dots.
\end{equation}
Here, we disallow $n = 0$ as it leads to $\lambda = -\alpha_0^2 = 0$. Also, we don't include $n < 0$ because writing $n = -m$ with $m > 0$ gives
\begin{equation}
    c_{2m} \sin\paren*{\frac{-m \pi x}{\ell}} = -c_{2m} \sin\paren*{\frac{m \pi x}{\ell}}
\end{equation}
and the minus sign can be absorbed into the arbitrary constant.

Next, solving $\ddot{T} - c^2 \lambda_n T = 0$ with $\lambda_n = -\alpha_n^2 = -n^2\pi^2 / \ell^2$ gives
\begin{equation}
    T_n(t) = c_{3n} \cos\paren*{\frac{n \pi ct}{\ell}} + c_{4n} \sin\paren*{\frac{n \pi ct}{\ell}}.
\end{equation}
Overall,
\begin{equation}
    u_n(x,t) = \paren*{a_{n} \cos\paren*{\frac{n \pi ct}{\ell}} + b_{n} \sin\paren*{\frac{n \pi ct}{\ell}}} \sin\paren*{\frac{n \pi x}{\ell}}
\end{equation}
where $a_n, b_n$ are arbitrary constants to be determined by the initial conditions.

Since the given PDE is linear, we apply the linear superposition principle to obtain the general solution
\begin{equation}
    u(x,t) = \sum_{n=1}^{\infty} \paren*{a_{n} \cos\paren*{\frac{n \pi ct}{\ell}} + b_{n} \sin\paren*{\frac{n \pi ct}{\ell}}} \sin\paren*{\frac{n \pi x}{\ell}}.
\end{equation}

In order to determined the constants $a_n$ and $b_n$, we use the initial data. We note that
\begin{equation}
    u(x,0) = f(x)
    \implies
    \sum_{n=1}^{\infty} a_n \sin\paren*{\frac{n \pi x}{\ell}} = f(x).
\end{equation}
This is a Fourier sine-series. By recognizing that $\set{ \sin\paren*{\frac{n \pi x}{\ell}} }$ form an orthogonal set of functions over $[0, \ell]$, we deduce the expression for $a_n$ to be
\begin{equation*}
    a_n = \frac{2}{\ell} \int_0^\ell f(x) \sin\paren*{\frac{n \pi x}{\ell}} \,dx.
\end{equation*}
Likewise,
\begin{equation}
    u_t (x,0) = g(x)
    \implies
    \sum_{n=1}^{\infty} b_n \paren*{\frac{n \pi}{\ell}} \sin\paren*{\frac{n \pi x}{\ell}} = g(x).
\end{equation}
This is again a Fourier sine-series, and by analogy with the previous calculation, we have
\begin{equation*}
    b_n = \frac{2}{n \pi c} \int_0^\ell g(x) \sin\paren*{\frac{n \pi x}{\ell}} \,dx.
\end{equation*}

Therefore, the complete solution for the vibrating string problem~\eqref{eq:vibrating-string-problem-h} (in the homogenous case) is
\begin{equation}
\begin{gathered}
    u(x,t) = \sum_{n=1}^{\infty} \paren*{a_{n} \cos\paren*{\frac{n \pi ct}{\ell}} + b_{n} \sin\paren*{\frac{n \pi ct}{\ell}}} \sin\paren*{\frac{n \pi x}{\ell}},\\
    a_n = \frac{2}{\ell} \int_0^\ell f(x) \sin\paren*{\frac{n \pi x}{\ell}} \,dx,
    \quad
    b_n = \frac{2}{n \pi c} \int_0^\ell g(x) \sin\paren*{\frac{n \pi x}{\ell}} \,dx.
\end{gathered}
\end{equation}
We observe that for all $n$, $a_n = 0$ if $f(x) \equiv 0$ and, similarly, $b_n = 0$ if $g(x) \equiv 0$.

\subsection{The Heat Conduction Problem (Homogenous Case)}
Consider a thin, conducting, homogenous rod of length $\ell$. Let $u = u(x,t)$ denote the temperature at position $0 \leq x \leq \ell$ along the rod at time $t \geq 0$. We arrange for the ends $x=0$ and $x=\ell$ to always remain at temperature $0$, and give the rod an initial temperature profile $f(x)$. The temperature profile at later times is then modelled by the heat equation along with the following initial-boundary data.
\begin{equation}
\begin{gathered}
    u_t = k \uxx, \quad x \in [0, \ell], \quad t \geq 0\\
    u(x,0) = f(x), \quad x \in [0, \ell]\\
    u(0,t) = u(\ell,t) = 0, \quad t \geq 0.
\end{gathered}
\label{eq:heat-conduction-problem-h}
\end{equation}
Here $k$ is a constant encoding thermal conductivity. We note that this is a second order linear homogenous PDE, and the boundary conditions are also homogenous. So, it is reasonable to try to apply the method of separation of variables.

We take the ansatz $u(x,t) = X(x) T(t)$ and look for the non-trivial solutions of the above problem. Under this ansatz the PDE becomes
\begin{equation}
    X(x) \dot{T}(t) - k X''(x) T(t) = 0, \quad x \in [0, \ell], \quad t \geq 0,
\end{equation}
and the boundary conditions take the form $X(0) = X(\ell) = 0$ for all $t \geq 0$. We can now separate the differential equation as
\begin{equation}
    X(x) \dot{T}(t) - k X''(x) T(t) = 0
    \implies
    \frac{X''(x)}{X(x)} = \frac{1}{k} \frac{\dot{T}(t)}{T(t)} = \lambda,
\end{equation}
where $\lambda$ is a constant. The resulting decoupled ODEs are
\begin{equation}
    X'' - \lambda X = 0
    \quad\text{and}\quad
    \dot{T} - k \lambda T = 0.
\end{equation}
These ODEs lead to different solutions based on the values of $\lambda$.

As in the (homogenous) vibrating string problem~\eqref{eq:vibrating-string-problem-h}, the case $\lambda \geq 0$ only leads to the trivial solution, while $\lambda = - \alpha^2 < 0$ gives
\begin{equation}
    X_n (x) = c_{2n} \sin\paren*{\frac{n \pi x}{\ell}}
    \quad n = 1, 2, 3, \dots,
\end{equation}
when $\lambda_n -\alpha_n^2 = -n^2 \pi^2 / \ell^2$. From $\dot{T} - k \lambda_n T = 0$ we obtain
\begin{equation}
    T_n(t) = c_{3n} \exp\paren*{-\frac{n^2 \pi^2 kt}{\ell^2}}.
\end{equation}

Combining $X_n$ and $T_n$ gives,
\begin{equation}
    u_n(x,t) = a_{n} \sin\paren*{\frac{n \pi x}{\ell}} e^{-(n\pi/\ell)^2 kt}
\end{equation}
where $a_n$ is an arbitrary constant.

Since the given PDE is linear, we apply the linear superposition principle to obtain the general solution
\begin{equation}
    u(x,t) = \sum_{n=1}^{\infty} a_{n} e^{-(n\pi/\ell)^2 kt} \sin\paren*{\frac{n \pi x}{\ell}}.
\end{equation}

In order to determined the constants $a_n$, we use the initial data.
\begin{equation}
    u(x,0) = f(x)
    \implies
    \sum_{n=1}^{\infty} a_n \sin\paren*{\frac{n \pi x}{\ell}} = f(x).
\end{equation}
This is the same Fourier sine-series that we obtained in the case of the vibrating string problem. Following the same approach, we conclude that
\begin{equation*}
    a_n = \frac{2}{\ell} \int_0^\ell f(x) \sin\paren*{\frac{n \pi x}{\ell}} \,dx.
\end{equation*}

Therefore, the complete solution for the heat conduction problem~\eqref{eq:heat-conduction-problem-h} (in the homogenous case) is
\begin{equation}
\begin{gathered}
    u(x,t) = \sum_{n=1}^{\infty} a_{n} e^{-(n\pi/\ell)^2 kt} \sin\paren*{\frac{n \pi x}{\ell}},
    \quad
    a_n = \frac{2}{\ell} \int_0^\ell f(x) \sin\paren*{\frac{n \pi x}{\ell}} \,dx.
\end{gathered}
\end{equation}

\end{document}